{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fse"
      ],
      "metadata": {
        "id": "sHFjuFqr2wo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download zh_core_web_sm\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "2cYCCEHW3Ktf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the data\n",
        "from google.colab import drive\n",
        "import json\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "matched_file_path = '/content/drive/MyDrive/bidirection_matched_recipes.json'\n",
        "\n",
        "with open(matched_file_path, 'r') as f:\n",
        "  data = json.load(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4ReNz4F28J1",
        "outputId": "d2ce3dab-85bf-4d7c-9847-1c2403223a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data preprocessing\n",
        "import spacy\n",
        "\n",
        "nlp_cn = spacy.load(\"zh_core_web_sm\")\n",
        "nlp_en = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def corpus_extraction(json_field):\n",
        "  corpus, tokens = [], []\n",
        "  for recipe in data:\n",
        "    for value in recipe[json_field]:\n",
        "      corpus.append(value)\n",
        "\n",
        "  for sent in corpus:\n",
        "    doc = nlp_en(sent)\n",
        "    tokens.append([token.text for token in doc])\n",
        "  return tokens\n"
      ],
      "metadata": {
        "id": "XZtnmTdL3EBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cn_tok_sent = corpus_extraction('cn_steps')\n",
        "en_tok_sent = corpus_extraction('en_steps')"
      ],
      "metadata": {
        "id": "G5o6HNe79Ha_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fasttext embeddings\n",
        "from gensim.models import FastText\n",
        "from fse import Average, IndexedList\n",
        "\n",
        "def get_fasttext_embed(sentences):\n",
        "  ft = FastText(sentences, min_count=1, vector_size=10)\n",
        "  model = Average(ft)\n",
        "  model.train(IndexedList(sentences))\n",
        "  model.sv.similarity(0,1)\n",
        "\n",
        "en_model = get_fasttext_embed(en_tok_sent)\n",
        "get_fasttext_embed(en_tok_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxAltyhF3V9L",
        "outputId": "905961b9-a2c1-4fdd-9c18-4765417f6dbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fse.models.base_s2v:found 243 empty sentences\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.29277593"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cn_model = get_fasttext_embed(cn_tok_sent)\n",
        "get_fasttext_embed(cn_tok_sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYivSGkB5OPl",
        "outputId": "fc5cc998-ac27-4ad8-c681-399ee6d838d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:fse.models.base_s2v:found 2 empty sentences\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6123755"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_model.wv.most_similar(\"锅\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ1H-5_G56My",
        "outputId": "7c9db212-e390-47c3-971a-0cdce8e1df2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('looking', 0.7993849515914917),\n",
              " ('Rotating', 0.7883195281028748),\n",
              " ('rotating', 0.787180483341217),\n",
              " ('tilting', 0.7763185501098633),\n",
              " ('bubbling', 0.7753626108169556),\n",
              " ('decorating', 0.7650951147079468),\n",
              " ('precooking', 0.7610251307487488),\n",
              " ('eating', 0.7606989145278931),\n",
              " ('Looking', 0.7566357851028442),\n",
              " ('Checking', 0.754292905330658)]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cn_model.wv.most_similar(\"锅\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUJICs7ZFX9t",
        "outputId": "fd0a8070-e8ca-4c6e-8859-451b01fddf60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('锅中', 0.9466560482978821),\n",
              " ('锅中焯', 0.9466060996055603),\n",
              " ('锅中添', 0.9442524313926697),\n",
              " ('锅里', 0.9430060386657715),\n",
              " ('锅内', 0.9427359700202942),\n",
              " ('锅中调', 0.9415774345397949),\n",
              " ('原炒锅', 0.9406287670135498),\n",
              " ('锅中水', 0.9404528141021729),\n",
              " ('锅里油', 0.9385949969291687),\n",
              " ('锅内盖', 0.9381129741668701)]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# saving the embeddings in a txt file\n",
        "from google.colab import files\n",
        "\n",
        "def save_and_download(lang, sentences, model):\n",
        "  with open(f'{lang}_token_embeds.txt', \"w\") as fw:\n",
        "    for sent in sentences:\n",
        "      for word in sent:\n",
        "        embed = model.wv[word]\n",
        "        fw.write(\"{}{}\\n\".format(word, embed))\n",
        "    files.download(f'{lang}_token_embeds.txt') \n",
        "\n",
        "\n",
        "save_and_download('en', en_tok_sent, en_model)\n",
        "save_and_download('cn', en_tok_sent, en_model)"
      ],
      "metadata": {
        "id": "DthbLttJTqCX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}